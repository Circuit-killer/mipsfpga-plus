<html>
<head>
<title>MIPSfpga 2.0. Lab YP4 - The first glance into caches</title>

<style>

a, body, td
{
    font-family : 'Lucida Sans Unicode', 'Lucida Grande', sans-serif;
    font-size   : 12px;
}

pre
{
    font-family : 'Lucida Console', Monaco, monospace;
    font-size   : 12px;
}

</style>
</head>
<body>
<p><big><big><b>MIPSfpga 2.0. Lab YP4 - The first glance into caches</b></big></big></p>
<p><big><b>1.  Introduction</b></big></p>

<p>This lab demonstrates how the work of CPU cache can be directly observed
in the most obvious and straigtforward fashion when running MIPSfpga-based
system on FPGA board.  During this lab a student first makes the design
clock running really slow (a dozen of beats per second), and then the
student's program fills a two-dimentional memory array in one of two
different ways: either with moving row index first or with moving column
index first.  The resulting cache hit and miss patterns are clearly visible
on blinking LED, which is connected to a signal that indicates cache fill
line request.  The student can see that these patterns are different for
raw-first and column-first runs.</p>

<p>Each cache line in MIPSfpga CPU cache holds four 32-bit words.  As a
result, when the program fills the memory array by moving column index
first, the pattern is going to be "cache miss - hit - hit - hit - miss - hit
- hit - hit - miss ...".  However when the program fills the array by moving
raw index first, the pattern is going to be a series of cache misses
followed by a long series of cache hits, since a large portion of the array
is already in the cache.</p>

<p>This lab does not attempt to measure, quantify or analyze cache behaviour
in details.  The only goal of this lab is to create "A-ha" moment for a
student who wants to visualize for himself the role a CPU cache plays in the
computer system.  The precise analysis requires using different methods, for
example performance counters, as described in other cache-related labs in
MIPSfpga 2.0 package.</p>
<p><big><b>2.  The theory of operation</b></big></p>

<p>Why do we need CPU cache?  It solves the problem of so-called
"processor-memory performance gap".  The issue is: during the past decades
the speed of CPUs grew faster than the speed of dynamic memory, used for
storing a large amount of data.  This difference in growth is illustrated on
<b><font color=blue>Figure 1</font></b>.  As a result, without cache, a
typical transaction (fetch, load or store) from CPU to the memory could take
the same amount of time (the same number of clock cycles) as tens, sometimes
a hundred or more arithmetic operations inside the CPU.  It means that with
a typical memory-intensive application a CPU without caches would waste most
program execution time idling, waiting to complete the memory
operations.</p>

<p><b><font color=blue>Figure 1.  Processor-memory performance gap, from
Computer Architecture: A Quantitative Approach by David A. Patterson and
John L. Hennessy </font></b> </p>

<img width=500
src="http://www.silicon-russia.com/wp-content/uploads/2016/09/KgYa8BM.png"
/>

<p>One of the best descriptions of cache used in MIPS CPUs is in book <a
href="https://www.amazon.com/Second-Morgan-Kaufmann-Computer-Architecture/dp/0120884216">See
MIPS Run, Second Edition by Dominic Sweetman</a>.  A fragment of this
description is below:</p>

<blockquote>

<p>The cache's job is to keep a copy of memory data that has been recently
read or written, so it can be returned to the CPU quickly.  For L1 caches,
the read must complete in a fixed period of time to keep the pipeline
running.</p>

<p>MIPS CPUs always have separate L1 caches for instructions and data
(I-cache and D-cache, respectively) so that an instruction can be read and a
load or store done simultaneously.</p>

<p>Conceptually, a cache is an associative memory, a chunk of storage where
data is deposited and can be found again using an arbitrary data pattern as
a key.  In a cache, the key is the full memory address.  Produce the same
key back to an associative memory and you'll get the same data back again. 
A real associative memory will accept a new item using an arbitrary key, at
least until it's full; however, since a presented key has to be compared
with every stored key simultaneously, a genuine associative memory of any
size is either hopelessly resource hungry, slow, or both.</p>

<p>So how can we make a useful cache that is fast and efficient?  <b><font
color=blue>Figure 2</font></b> shows the basic layout of the simplest kind
of cache, the direct-mapped cache used in most MIPS CPUs up to the 1992
generation.</p>

<p>The direct-mapped arrangement uses a simple chunk of high-speed memory
(the cache store) indexed by enough low address bits to span its size.  Each
line inside the cache store contains one or more words of data and a cache
tag field, which records the memory address where this data belongs.</p>

<p>On a read, the cache line is accessed, and the tag field is compared with
the higher addresses of the memory address; if the tag matches, we know
we've got the right data and have "hit" in the cache.  Where there's more
than one word in the line, the appropriate word will be selected based on
the very lowest address bits.</p>

<p>If the tag doesn't match, we've missed and the data will be read from
memory and copied into the cache.  The data that was previously held in the
cache is simply discarded and will need to be fetched from memory again if
the CPU references it.</p>

<center>

<p><b><font color=blue>Figure 2.  Direct-mapped cache.</font></b></p>

<img width=500
src="http://www.silicon-russia.com/wp-content/uploads/2016/10/direct_mapped_cache.png"
/>

</center>

<p>A direct-mapped cache like this one has the property that, for any given
memory address, there is only one line in the cache store where that data
can be kept.<sup>1</sup> That might be good or bad; it's good because such a
simple structure will be fast and will allow us to run the whole CPU faster. 
But simplicity has its bad side too: If your program makes repeated
reference to two data items that happen to share the same cache location
(presumably because the low bits of their addresses happen to be close
together), then the two data items will keep pushing each other out of the
cache and efficiency will fall drastically.  A real associative memory
wouldn't suffer from this kind of thrashing, but it is too slow and
expensive.</p>

<p>A common compromise is to use a two-way set-associative cache—which is
really just a matter of running two direct-mapped caches in parallel and
looking up memory locations in both of them, as shown in <b><font
color=blue>Figure 3</font></b>.</p>

<sup>1.</sup> <small>In a fully associative memory, data associated with any
given memory address (key) can be stored anywhere; a direct-mapped cache is
as far from being content addressable as a cache store can be.</small>

<center>

<p><b><font color=blue>Figure 3.  Two-way set-associative
cache.</font></b></p>

<img width=500
src="http://www.silicon-russia.com/wp-content/uploads/2016/10/2_way_set_associative_cache.png"
/>

</center>

<p>Now we've got two chances of getting a hit on any address.  Four-way
setassociative caches (where there are effectively four direct-mapped
subcaches) are also common in on-chip caches.</p>

<p>In a multiway cache there's more than one choice of the cache location to
be used in fixing up a cache miss, and thus more than one acceptable choice
of the cache line to be discarded.  The ideal solution is probably to keep
track of accesses to cache lines and pick the "least recently used" ("LRU")
line to be replaced, but maintaining strict LRU order means updating LRU
bits in every cache line every time the cache is read.  Moreover, keeping
strict LRU information in a more-than-four-way set-associative cache becomes
impractical.  Real caches often use compromise algorithms like "least
recently filled" to pick the line to discard.</p>

</blockquote>

<p>CPU caches exploit so-called principle of locality of memory access
patterns found in almost all programs.  Below is the explanation for two
major types of locality from Wikipedia and <b><font color=blue>Figure
4</font></b> that illustrates the patterns with more specifics.  The
understanding of this principle is relevant to this lab because it explains,
for example, why MIPSfpga cache loads four words on cache miss (the cache
line) rather than just one word.</p>

<blockquote>

<p>From <a
href="https://en.wikipedia.org/wiki/Locality_of_reference">https://en.wikipedia.org/wiki/Locality_of_reference</a>:<p>

<ul>

<li>Temporal locality: If at one point a particular memory location is
referenced, then it is likely that the same location will be referenced
again in the near future.</li>

<li>Spatial locality: If a particular storage location is referenced at a
particular time, then it is likely that nearby memory locations will be
referenced in the near future.</li>

</ul>

</blockquote>

<center>

<p><b><font color=blue>Figure 4.  Memory access patterns from <a
href="https://www.coursera.org/learn/comparch">Computer Architecture</a>
course by David Wentzlaff from Princeton University.  2011.</font></b></p>

<img width=500
src="http://www.silicon-russia.com/wp-content/uploads/2016/10/cache_locality.png"
/>

</center>

<p>Finally, <b><font color=blue>Figure 5</font></b> shows the structures
associated with each cache line in MIPS microAptiv UP processor core.  The
particular configuration of this core used in MIPSfpga has 2-way
set-associativity for both instruction and data caches; each cache way has
size of 2 KB in both I-cache and D-cache.  The parameters of caches used
during the synthesis can be found in Verilog header file
<i>m14k_config.vh</i> located in the directory <i>core_rtl</i>:</p>

<blockquote><p>File <i>core_rtl/m14k_config.vh</i></p>
<pre>                           

// *************************************************************************
// Cache module parameters
// Not used with scache or cache stub modules
// *************************************************************************
// Cache Associativity
//      1-4 way set associative

`define M14K_ICACHE_ASSOC 2
`define M14K_DCACHE_ASSOC 2

// Cache Way Size
//      Size/Way in KB
//      1,2,4,8,16 KB

`define M14K_ICACHE_WAYSIZE 2
`define M14K_DCACHE_WAYSIZE 2



// *************************************************************************
// Cache Controller parameters
// *************************************************************************
// ! If changing manually, remember to change WS Ram Width below to match !
// Maximum Cache Associativity
//      1-4 way set associative (including Spram)

`define M14K_MAX_IC_ASSOC 2
`define M14K_MAX_DC_ASSOC 2

</pre></blockquote>

<center>

<p><b><font color=blue>Figure 5.  The structures associated with each cache
line in MIPS microAptiv UP processor core processor core.</font></b></p>

<img
src="http://www.silicon-russia.com/wp-content/uploads/2016/10/mips_microaptiv_up_cache.png"
/>

</center>

<p><big><b>3.  Lab steps</b></big></p>

<p>This section outlines the sequence of steps, necessary to complete the
lab.  Almost all generic steps in this lab are the same as in <i>MIPSfpga
2.0 Lab YP1.  Using MIPSfpga with Serial Loader Flow that does not require
BusBlaster board and OpenOCD software</i>.  Such generic steps are not
described in this section.  Only the steps different from <i>Lab YP1</i> are
explained in details.</p>

<p><big><b>3.1.  Connect the board to the computer</b></big></p>

<p>For <i>Digilent</i> boards, such as <i>Nexys4</i>, <i>Nexys4 DDR</i> or
<i>Basys3</i>, this step is obvious.  For <i>Altera/Terasic</i> boards some
additional steps required:</p>

<ol>

<li>Connect USB-to-UART connector to FPGA board. 
Either <i>FT232RL</i> or <i>PL2303TA</i> that you can by from AliExpress or
RadioShack will do the job.  <i>TX</i> output from the connector (green wire
on <i>PL2303TA</i>) should go to pin 3 from right bottom on Terasic DE0,
DE0-CV, DE1, DE2-115 (right top on DE0-Nano) and <i>GND</i> output (black
wire on <i>PL2303TA</i>) should be connected to pin 6 from right bottom on
Terasic DE0, DE0-CV, DE1, DE2-115 (right top on DE0-Nano).  Please consult
photo picture in <i>Lab YP1</i> to avoid short-circuit or other connection
problems.</li> </ol>

<li>For <i>FT232RL</i> connector: make sure to set 3.3V/5V jumper on
<i>FT232RL</i> part to 3.3V.</li>

<li>For the boards that require external power in addition to the power that
comes from USB, connect the power supply.  The boards that require the extra
power supply include <i>Terasic DE2-115</i>.</li>

<li>Connect FPGA board to the computer using main connection cable provided
by the board manufacturers.  Make sure to put USB cable to the right jack
when ambiguity exists (such as in <i>Terasic DE2-115</i> board).</li>

<li>Make sure to power the FPGA board (turn on the power switch) before
connecting the UART cable from USB-to-UART connector to the computer. 
Failing to do so may result in electric damage to the board.</li>

<li>Connect USB-to-UART connector to FPGA board.</li>

</ol>

<p><big><b>3.2.  Select the appropriate hardware system configuration for
the lab</b></big></p>

<p>Before running synthesis it is necessary to review and possibly modify
the file <i>system_rtl/mfp_ahb_lite_matrix_config.vh</i> that includes a set
of Verilog <i>`define</i> statements that determine the functionality of the
synthesized MIPSfpga system.  The configuration should be the following:</p>

<blockquote><p>File <i>system_rtl/mfp_ahb_lite_matrix_config.vh</i></p>
<pre>

//
//  Configuration parameters
//

// `define MFP_USE_WORD_MEMORY
// `define MFP_INITIALIZE_MEMORY_FROM_TXT_FILE
   `define MFP_USE_SLOW_CLOCK_AND_CLOCK_MUX
   `define MFP_USE_UART_PROGRAM_LOADER
// `define MFP_DEMO_LIGHT_SENSOR
   `define MFP_DEMO_CACHE_MISSES
// `define MFP_DEMO_PIPE_BYPASS

</pre></blockquote>

<p><big><b>3.3.  Run the synthesis and configure the FPGA with the synthesized MIPSfpga system</b></big></p>

<p>This step is identical to the synthesis step in <i>Lab YP1</i></p>

<p><big><b>3.4.  Go to the lab directory and clean it up</b></big></p>

<p>Under Windows:</p>

<blockquote><pre>
cd programs\lab_yp4
00_clean_all.bat
</pre></blockquote>

<p>Under Linux:</p>

<blockquote><pre>
cd programs/lab_yp4
00_clean_all.sh
</pre></blockquote>

<p><big><b>3.5.  Review the lab program code</b></big></p>

<p>The main program is located in file <i>programs/lab_yp4/main.c</i>.</p>

<p>The loop at the beginning (<i>"while ((MFP_SWITCHES & 4) == 0) ;"</i>) is
needed so that the program can start with high clock speed (25 MHz) and the
switch to very low clock speed (12.5 Hz) happens only after you first switch
the speed by turning on switch one and then let the program to continue by
turning on switch two.</p>

<p>The program has two variants - with uncommented <i>"a [i][j] = i +
j;"</i> and with uncommented <i>"a [j][i] = i + j;"</i>.  For the first run
make sure <i>"a [i][j] = i + j;"</i> is uncommented and <i>"a [j][i] = i +
j;"</i> is commendted:</p>

<img
src="http://www.silicon-russia.com/wp-content/uploads/2016/10/02_cache_misses_main_c_1.png"
/>

<p><big><b>3.6. The first run</b></big></p>

<p>Following the procedure described in <i>Lab YP1</i>, compile and link the
program, generate Motorola S-Record file and upload this file into the
memory of the synthesized MIPSfpga-based system on the board.</p>

<p>Under Windows:</p>

<ol>

<li>cd programs\lab_yp4</li>

<li>run 02_compile_and_link.bat</li>

<li>run 08_generate_motorola_s_record_file.bat</li>

<li>run 11_check_which_com_port_is_used.bat</li>

<li>edit 12_upload_to_the_board_using_uart.bat based on the result from the
previous step - set the working port in “set a=” assignment</li>

<li>run 12_upload_to_the_board_using_uart.bat</li>

</ol>

<p>Under Linux:</p>

<ol>

<li>cd programs/lab_yp4</li>

<li>run ./02_compile_and_link.sh</li>

<li>run ./08_generate_motorola_s_record_file.sh</li>

<li>run ./11_check_which_com_port_is_used.sh</li>

<li>edit ./12_upload_to_the_board_using_uart.sh based on the result from the
previous step - set the working port in “set a=” assignment</li>

<li>./run 12_upload_to_the_board_using_uart.sh</li>

</ol>

<img
src="http://www.silicon-russia.com/wp-content/uploads/2016/10/02_cache_misses_main_c_2.png"
/>

<blockquote><p>File <i>system_rtl/mfp_ahb_lite_matrix_config.vh</i></p>
<pre>

</pre></blockquote>


5.2. An example of student experiment: switchable clock enables to directly observe CPU cache in action

Switchable clock allows to show the internals of the processor to the students live. Here is an example: a signal that indicates cache eviction is connected to an external LED. Now it is possible to observe cache misses when a program fills a two-dimensional array. This example can be run twice: when the array is filled by columns and when the array is filled by rows. These runs generate different patters of LED blinking.

Specifically, since cache line of MIPS microAptiv UP has size of four words, the following pattern appear when filling the array column after column: miss hit hit hit miss hit hit hit ... When the array is filled row by row, the observed pattern is different: miss miss miss ... 8 times ... miss hit hit hit ... 24 times ...

To run the demonstration program below, a user has to start with fast clock, go through the initialization sequence with switch 2 off, then switch the clock from 25 MHz to 12 Hz, turn switch 2 on and observe the pattern. After that a user has to modify the program, compile and load it to the board, and run the whole thing again.

Note that such demos are very sensitive to compiler optimizations, so the code should be kept simple and straightforward, otherwise the compiler moves actions around and the pattern becomes unclear. Also note that the first ~3 cache misses likely result from instruction fetches filling L1 instruction cache, not L1 data cache:





 and upload Selecting the appropriate hardware system configuration for
the lab</b></big></p>



<blockquote><p>File <i>04_disassemble.bat</i></p><pre>                                
</pre></blockquote>
</body>
</html>
